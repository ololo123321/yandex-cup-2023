Решение - ансамбль из моделей разных семейств:
* conformer - 11 штук с разными гиперпараметрами. 
Для добавления вариативности брал реализации из torchaudio и transformers: во второй есть relative embeddings (как в оригинальной статье) и layer dropout. 
Модели этого семейства зашли лучше всего, и итоговый ансамбль примерно наполовину состоит из них.
* transformer - просто трансформер энкодер с 6 слоями. Чуток докинуло на валидации использовать sliding window маску с шириной окна {9, 17, 31} + добавление аттеншена на "все с первым" и "первый со всеми". 
Также использовал relative embeddings в mha. В ансамбле 2 модели.
* resnet и inception - описано здесь: https://arxiv.org/abs/1909.04939, реализация на торче: https://github.com/okrasolar/pytorch-timeseries/tree/master/src/models. 
Особо ничего не менял, только попробовал в resnet свёрточный блок подменить на ECA (efficient channel attention). Немного докидывало. В лучшем ансамбле 3 вариации resnet и 2 - inception.

Итого в лучшем ансамбле 18 моделей. 
Все их учил на asymmetric focal loss: https://arxiv.org/abs/2009.14119. По сути обычный фокал лосс со следующими доработками: 1) можно с разной степенью "приглушать" влияние простых позитивов и негативов на лосс (своя гамма для позитивов и своя - для негативов), 2) можно совсем "выключать" простые негативы: такие, на которых вероятность ниже p, где p - гиперпараметр. 
Вариьруя эти три параметра можно добиваться более разнообразных предиктов даже в рамках одной архитектуры. 
Заметил, что такие модели и лучше в ансамбле: мб потому что их вероятности не вырождены в 0 или 1, как это часто бывает при обучении на bce, а значит и ансамбль не превращается в простое головосование.
Каждую модель учил на 3 разбиениях на 10 фолдов (один раз разбил на 10 фолдов, взял 3/10 пар (train, valid)), а предикты усреднях в рамках одной модели. На самом деле ощутимый прирост есть только при добавлении второго фолда (+0.004 на паблике). Третий фолд докинул менее 0.001.

Решил немного заморочиться на тему отбора моделей и их весов в ансамбле: за время туринра моделей накопилось больше сотни, и на глаз в какой-то момент стало очень сложно выбирать лучшее подмножество. 
Много всего перепробовал: "на глазок", lasso, гиперопт. Лучше всего сработал beam search.
Также думал на тему взвешивания: было непросто побить бейзлайн с усреднением лучших моделей (логрег и другие стекинги не помогали). В итоге решил зашить взвешивание в бим сёрч.

В качестве итогового решения за минут 10 до конца туринра решил залить чуть другой ансамбль (19 моделей): качество просело, но не критично: 0.3120 против 0.3128 у лучшего ансамбля, который описал выше.
